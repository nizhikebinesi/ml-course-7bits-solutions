# Первый семестр курса

## План

1. Таблицы с данными. Признаки и их типы. Законы распределения признаков и зависимость между признаками (тут же: коэффициент корреляции).
2. Проблема пропущенных данных. Методы восстановления. Восстановление с помощью метрик и коэфф корреляции. Приложение всего этого в рекомендательных системах.
3. Выбросы. Алгоритмы обнаружения выбросов. Критерии Пирса и Шавене (Chauvenet). Прочие методы обнаружения выбросов и обнаружение новизны в новой выборке (по сравнению со старой).
4. Кластеризация. Алгоритмы (метрические и k-means). Обнаружение выбросов с помощью кластеризации. 
5. Задача предсказания значения признака. Тренировочная и тестовая выборка. Общий план работы работы алгоритма предсказания (разбиение на тестовую и тренировочную выборку). Кросс-валидация. Переобучение.
6. Задача регрессии. Оценка качества МАЕ, МАРЕ и пр. Методы регрессии: линейная модель, метрические (типа ближайшего соседа).
7. Задача классификации. Общая теория задач бинарной классификации. Таблица ошибок. Ошибки первого и второго рода. Показатели качества. Самый простой классификатор.
8. Методы классификации (изучаем по порядку): метрические, Байес, деревья, случайный лес, SVM. Для каждого алгоритма разбирается пример его работы.
9. Предсказание вероятности принадлежности классам. Когда такой подход оправдан. Показатели качества для таких алгоритмов (ROC, AUC)
10. Логистическая регрессия (она как раз и предсказывает вероятность принадлежности классам).
11. Анализ множества признаков. Информативность признака. Синтез новых признаков. Методы преобразования признаков. Метод главных компонент и другие методы, связанные с разложение матрицы признаков.
12. Изменение числа объектов (при несбалансированной выборке). Синтетические образы, расщепление образа на несколько других, oversampling and undersampling.
